{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill Advisor model using Doc2Vec and K-mean clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Read the cleaned json file generated from wordtovec notebook in dataframe\n",
    "\n",
    "df = pd.read_json('wordtovec_cleaned.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Get the skills and corresponsing job titiles \n",
    "skill_list = df.skill.values.tolist()\n",
    "job_label = df.job_name.values.tolist()\n",
    "\n",
    "documents = [TaggedDocument(doc, [job_label[i]]) for i, doc in enumerate(skill_list)]\n",
    "\n",
    "\n",
    "# make doc2vec model\n",
    "model1 = Doc2Vec(documents, vector_size=50, window=3, min_count=5, \n",
    "                 workers=4, dbow_words=1, dm=0)\n",
    "# train model\n",
    "model1.train(documents=documents, total_examples=model1.corpus_count, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and t-SNE conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load wordtovec notebook \n",
    "# Keep both notebooks in the same folder\n",
    "from ipynb.fs.full.wordtovec import tsneconversion, cluster_visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style(\"darkgrid\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "    \n",
    "    \n",
    "df_tsne, Y = tsneconversion(model1, 'cook', ['data scientist', 'janitor', 'waiter'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_visualization(df_tsne, 'cook', Y, 500, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job_title vectors\n",
    "\n",
    "unique_jobs = set(job_label)\n",
    "job_vectors = []\n",
    "for job in unique_jobs:\n",
    "    job_vectors.append(model1[job])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get skill Vectors\n",
    "\n",
    "skill_vectors = []\n",
    "for skill in model1.wv.vocab.keys():\n",
    "    skill_vectors.append(model1.wv[skill])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all vectors \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "job_vectors = np.array(job_vectors)\n",
    "skill_vectors = np.array(skill_vectors)\n",
    "all_vec = np.concatenate((job_vectors, skill_vectors))\n",
    "skills_and_jobs = list(unique_jobs) + list(model1.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run K-means\n",
    "\n",
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer\n",
    "\n",
    "NUM_CLUSTERS = 15\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=50)\n",
    "assigned_clusters = kclusterer.cluster(all_vec, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization\n",
    "\n",
    "# Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
    "reduc = PCA(n_components=50).fit_transform(all_vec)\n",
    "# Finds t-SNE coordinates for 2 dimensions\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with skills and corresponding cluster number and TSNE co-ordinates\n",
    "\n",
    "df_cluster = pd.DataFrame({'skill': skills_and_jobs, 'cluster': assigned_clusters, \n",
    "                           'X': Y[:,0], 'Y': Y[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLuser plot for secretary\n",
    "secretary = df_cluster[df_cluster.skill == 'secretary']\n",
    "secretary.loc[:,\"color\"] = \"red\"\n",
    "clust_number = secretary.cluster.values[0]\n",
    "df_secretary = df_cluster[df_cluster.cluster == clust_number]\n",
    "\n",
    "N_sample = 10\n",
    "color = [\"blue\"] * N_sample\n",
    "df_plot = df_secretary.sample(N_sample, random_state=10)\n",
    "df_plot[\"color\"] = color\n",
    "df_plot = pd.concat([secretary, df_plot])\n",
    "df_plot = df_plot.reset_index(drop=True)\n",
    "\n",
    "cluster_visualization(df_plot, 'secretary', Y, 0, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
